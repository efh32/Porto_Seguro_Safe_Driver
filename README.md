# Porto Seguro Safe Driver Project

## Project Description <a name="descrip"/> 

This model predicts the probability a driver will initiate an auto insurance claim.  The data comes from the following Kaggle Competition: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction. 

## Table of Contents

[Project Description](#descrip) 

[Background](#background)

[Requirements](#requirements)

[How to Run](#run)

[License](#license)
 
## Background <a name="background"/>

[Additional Project Information](#additional)

[File Information](#fileInfo)
 
[Helpful Links](#concepts)

### Additional Project Information <a name="additional"/>

The submissions are evaluated using the Normalized Gini Coefficient and the probabilities generated by the model are used to rank the test data.  The following link has information about how the model is scored: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction#evaluation.  


### File Information <a name="fileInfo"/>

1. explore_data.py - initial preprocessing of the data
    * Reads the raw train data and raw test data.  (Files from the competition)  
    * Removes features that have too many missing values.  
    * Imputes missing values with sklearn.preprocessing Imputer.  Replaces missing categorical data with the feature's mode.  Replaces missing continous data with the feature's mean.  
    * A feature is removed if the distributions are too similar between the two classes (claim and no claim).  
    * Checks the distributions of each column in test and train data.  If the test data and train data distribution differ the column is removed.    
    * Writes out the preprocessed train and test data.  
2. preprocess_data.py - augments data to fix class balance issue
    * Reads the preprocessed data created by explore_data.py. 
    * Creates training data and testing data for the model.  The training data contains 80% of the original train data.  The testing data contains the remaining 20% of the original train data.
    * Writes the training data and testing data to csv files.
    * Creates an augmented training set.  Takes 400,000 data points from training data that have a label of 0. Resamples data that have a label of 1 to 400,000.  This results in a balanced training set.  
    * Write out the autmented training data.
3. train_wide_and_deep.py - trains a TensorFlow model from the augmented training data.  The checkpoints are saved after the epoch.  This file may be run more than once. 
4. w_n_d_predict.py - produces a prediction for the testing data.  The higher the probability, the more likely the model believes the data is a claim.  
5. boosting_preprocess.py - creates new training data.  Removes data that have a prediction of below 0.5.  This new training data is used to perform further training for the model. 

### Helpful Links <a name="concepts"/>

1. How to use resample to increase or decrease label - https://elitedatascience.com/imbalanced-classes
2. Explains the Wide and Deep - https://www.tensorflow.org/tutorials/wide_and_deep


## Requirements <a name="requirements"/>

1. Python 3 - https://www.python.org/getit/
2. TensorFlow - https://www.tensorflow.org/install/
3. Scikit-learn - http://scikit-learn.org/stable/install.html
4. NumPy - https://www.scipy.org/scipylib/download.html
5. Pandas - https://pandas.pydata.org/pandas-docs/stable/install.html
6. Matplotlib - https://matplotlib.org/users/installing.html


## How to Run <a name="run"/>

1. Download the software listed in the [requirements section](#requirements)

2. Download the files from this repository.  Create a folder called "Data" located in the directory that contains the files downloaded from the repository.

3. Download the data from the [Porto Seguro competition](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/data) and store the data in the "Data" folder.  

4. Run the explore_data.py file in your IDE or terminal.  Be sure to uncomment and change line 17 so that the path to the directory that contains the Kaggle data is the argument in the os.chdir function.
```python
#os.chdir('path to directory containing downloaded data')

```
5. Run the preprocess_data.py file in your IDE or terminal.

6. Run train_wide_and_deep.py. 

6. (optional) Run the boosting_preprocess.py file.

7. (optional) Run train_wide_and_deep.py again.  Be sure to change the function found in lines 234 to 253 into the following:
```python
def maybe_download(train_data, test_data, train2_data=""):
  """Maybe downloads training data and returns train and test file names."""
  if train_data:
    train_file_name = train_data
  else:
    train_file_name = "training_data_2.csv"

  if test_data:
    test_file_name = test_data
  else:
    #test_file_name = "./data/test-1.csv"
    test_file_name = "testing_data_2.csv"
    
  if train2_data:
    train2_file_name = train2_data
  else:
    train2_file_name = "training_data_augmented_2.csv"
    #test_file_name = "./data/train-1.csv"
    
  return train_file_name, test_file_name, train2_file_name
```
note that the file names were changed to match the files created by boosting_preprocess.py.

8. Run w_n_d_predicty.py.  

## License <a name="license"/>

MIT License

Copyright (c) [year] [fullname]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.




